{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CSE 574 BCI PROJECT\n",
    "\n",
    "#pandas and numpy imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data Import for Eye Blink Data\n",
    "df=pd.read_excel(r'newEyeBlink.xlsx')\n",
    "data = df.to_numpy()\n",
    "data.shape\n",
    "\n",
    "#Data Import for Multi Physical and Imaginary Movement\n",
    "df3=pd.read_excel('s11mod.xlsx', sheet_name=None)\n",
    "dfconcat=pd.concat((df3[frame] for frame in df3.keys()), sort = True)\n",
    "dfconcat = dfconcat.fillna(0)\n",
    "data3 = dfconcat.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(data3, 42, 1) \n",
    "Y = data3[:,42]\n",
    "Y = np.where(Y=='right Fist', 'Right_Fist', Y) \n",
    "Y = np.where(Y=='left Fist', 'Left_Fist', Y)\n",
    "data_classes = np.unique(Y)\n",
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconcat = dfconcat.fillna(0)\n",
    "data3 = dfconcat.to_numpy()\n",
    "X = np.delete(data3, 42, 1) \n",
    "Y = data3[:,42]\n",
    "Y = np.where(Y=='right Fist', 'Right_Fist', Y) \n",
    "Y = np.where(Y=='left Fist', 'Left_Fist', Y)\n",
    "data_classes = np.unique(Y)\n",
    "X = X.astype(int)\n",
    "\n",
    "Y = np.where(Y=='Both_Fists',0, Y)\n",
    "Y = np.where(Y=='IMGINE_Both_Fists',1, Y)\n",
    "Y = np.where(Y=='IMGINE_Left_Fist', 2, Y)\n",
    "Y = np.where(Y=='IMGINE_Right_Fist', 3, Y)\n",
    "Y = np.where(Y=='Left_Fist', 4, Y)\n",
    "Y = np.where(Y=='Rest_Eyes_Closed', 5, Y)\n",
    "Y = np.where(Y=='Rest_Eyes_Open', 6, Y)\n",
    "Y = np.where(Y=='Right_Fist', 7, Y)\n",
    "Y = np.where(Y=='rest', 8, Y)\n",
    "Y = Y.astype(int)\n",
    "Y = np.array([Y]).transpose()\n",
    "\n",
    "XYstack = np.hstack((X,Y))\n",
    "display(XYstack)\n",
    "XY = XYstack[XYstack[:, -1] != 8]\n",
    "XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping = dict(zip(data_classes[0:8], range(0,8)))\n",
    "display(Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE RANDOM SAMPLING WITHOUT REPLACEMENT OF DATA\n",
    "#Can change sample size if you prefer\n",
    "idx = np.random.choice(XY.shape[0]-1, 50000, replace=False)\n",
    "XYsample = XY[idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DATA SPLIT AND ACCURACY MEASURE FOR KNN MODEL\n",
    "\n",
    "    from sklearn.model_selection import train_test_split \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(XYsample[:,0:65], XYsample[:,65], test_size=0.2)\n",
    "    neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "    neigh.fit(X_train,Y_train)\n",
    "    y_pred3 = neigh.predict(X_test)\n",
    "    # Making the prediction\n",
    "    display('KNN Classifier Score: ', metrics.accuracy_score(Y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch on KNN hyperparameter\n",
    "\n",
    "#define parameter range\n",
    "param_grid3 = {'n_neighbors' : [1, 3, 5, 7, 10, 12, 15, 16]}\n",
    "grid3 = GridSearchCV(KNeighborsClassifier(), param_grid3, refit = True, verbose = 3, cv = 4) \n",
    "#fit the model for grid search \n",
    "grid3.fit(X_train,Y_train)\n",
    "# grid predictions\n",
    "grid_prediction3 = grid3.predict(X_test)\n",
    "\n",
    "###GRID SEARCH OPTIMIZATION\n",
    "scores = grid3.cv_results_\n",
    "mean_scores1 = scores.get('split0_test_score')\n",
    "mean_scores2 = scores.get('split1_test_score')\n",
    "mean_scores3 = scores.get('split2_test_score')\n",
    "mean_scores4 = scores.get('split3_test_score')\n",
    "params = param_grid3.get('n_neighbors')\n",
    "_, KNN_plot = plt.subplots(1,1)\n",
    "KNN_plot.plot(params, mean_scores1, '-o', label = 'Split 1')\n",
    "KNN_plot.plot(params, mean_scores2, '-x', label = 'Split 2')\n",
    "KNN_plot.plot(params, mean_scores3, '-v', label = 'Split 3')\n",
    "KNN_plot.plot(params, mean_scores4, '-^', label = 'Split 4')\n",
    "\n",
    "KNN_plot.set_title(\"Grid Search Scores: K-Nearest Neighbors\", fontsize=16, fontweight='bold')\n",
    "KNN_plot.set_xlabel('K value', fontsize=14)\n",
    "KNN_plot.set_ylabel('Cross Validation Average Score', fontsize=14)\n",
    "KNN_plot.legend(loc=\"best\", fontsize=14)\n",
    "KNN_plot.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PLOT FOR PREDICTION\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "labels = ['Move Both Fists','Imagine Moving Both Fists','Imagine Moving Left Fist','Imagine Moving Right Fist','Left Fist','Rest Eyes Closed','Rest Eyes Open','Right Fist']\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(X_train)\n",
    "neigh.fit(X_train,Y_train)\n",
    "neighbors = 5\n",
    "samp = np.array([X_test[53,]])\n",
    "idx = neigh.kneighbors(samp, neighbors*3, return_distance = False)\n",
    "idx = idx.flatten()\n",
    "neighborplot = XYsample[idx,:]\n",
    "predicted_label = labels[np.argmax(np.bincount(neighborplot[0:neighbors,-1]))]\n",
    "display(predicted_label)\n",
    "display(neighborplot[:,-1])\n",
    "y = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "colors = ['#FF3333','#FF9933','#FFFF33','#80FF00','#00FFFF','#0080FF','#0000FF','#7F00FF']\n",
    "colors2 = ['#FFCCCC', '#FFE5CC', '#FFFFCC', '#E5FFCC', '#CCFFFF', '#CCE5FF', '#CCCCFF','#FFCCFF']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "\n",
    "for i in range(samp.shape[0]):\n",
    "    for j in range(neighbors):\n",
    "        xx = np.array([neighborplot[i*neighbors+j,0],samp[i,0]]) #neighborplot[i*neighbors+j,0]\n",
    "        yy = np.array([neighborplot[i*neighbors+j,1],samp[i,1]]) #[neighborplot[i*neighbors+j,1]\n",
    "        ax.plot(xx,yy, 'r--',color = 'gray')\n",
    "for i in range(8):\n",
    "    ax.scatter(neighborplot[neighborplot[:,-1] == i,0], neighborplot[neighborplot[:,-1] == i,1], label = labels[i], marker='o', s= 100, color=colors[i], edgecolor = 'gray')\n",
    "for i in range(samp.shape[0]):\n",
    "    ax.scatter(samp[i,0], samp[i,1], marker='*', s= 750, color='black') \n",
    "\n",
    "ax.legend()\n",
    "plt.title('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CONFUSION MATRIX FOR MULTICLASS KNN\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "KNN_CM = confusion_matrix(Y_test, y_pred3)\n",
    "plt.matshow(KNN_CM, cmap=plt.cm.get_cmap('Purples', 15));\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####PLOT OF ALL SAMPLE DATA AND LABELS (50,000 POINTS)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors\n",
    "h = 0.2\n",
    "X = X_train[:, :2]\n",
    "y = Y_train\n",
    "\n",
    "# Create color maps\n",
    "#    cmap_light = ListedColormap([ '#FFCCCC', '#FFE5CC', '#FFFFCC', '#E5FFCC', '#CCFFFF', '#CCE5FF', '#CCCCFF','#FFCCFF'])\n",
    "cmap_bold = ListedColormap(['#FF3333','#FF9933','#FFFF33','#80FF00','#00FFFF','#0080FF','#0000FF','#7F00FF','#FF00FF'])\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='distance')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# calculate min, max and limits\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict class using data and kNN classifier\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(facecolor=(1, 1, 1))\n",
    "#    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"8-Class classification (k = %i)\" % (neighbors)) #labels, number of neightbors\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data[:,0:14], data[:,14], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USING SCALED DATA\n",
    "X = np.vstack((X_train, X_test))\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train = X[0:X_train.shape[0],:]\n",
    "X_test = X[X_train.shape[0]:X.shape[0], :]\n",
    "display(data.shape, X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "#SVM Classifier \n",
    "svclass = SVC(kernel='linear', gamma = 'auto', C = 1000)\n",
    "svclass.fit(X_train,Y_train)\n",
    "#making the prediction \n",
    "y_pred1 = svclass.predict(X_test)\n",
    "display('SVM Classifier Score: ', metrics.accuracy_score(Y_test,y_pred1))\n",
    "\n",
    "#Decision Tree Classifier\n",
    "giniImp = DecisionTreeClassifier(criterion = \"gini\", random_state=100)\n",
    "giniImp.fit(X_train,Y_train)\n",
    "# make prediction \n",
    "y_pred2 = giniImp.predict(X_test)\n",
    "display('Decision Tree Classifier Score: ', metrics.accuracy_score(Y_test,y_pred2))\n",
    "\n",
    "#KNN Classifier \n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(X_train,Y_train)\n",
    "y_pred3 = neigh.predict(X_test)\n",
    "display('KNN Classifier Score: ', metrics.accuracy_score(Y_test,y_pred3))\n",
    "\n",
    "#Logisitic Regression Classifier\n",
    "lrmodel = LogisticRegression(multi_class = 'multinomial', solver = 'sag', C = 1000)\n",
    "lrmodel.fit(X_train,Y_train)\n",
    "# Making the prediction\n",
    "y_pred4 = lrmodel.predict(X_test)\n",
    "display('Logistic Regression Classifier Score: ', metrics.accuracy_score(Y_test,y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##USING ORIGINAL DATA\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data[:,0:14], data[:,14], test_size=0.2)\n",
    "\n",
    "#SVM Classifier \n",
    "svclass = SVC(kernel='linear', gamma = 'auto', C = 1000)\n",
    "svclass.fit(X_train,Y_train)\n",
    "# Making the prediction\n",
    "y_pred1 = svclass.predict(X_test)\n",
    "display('SVM Classifier Score: ', metrics.accuracy_score(Y_test,y_pred1))\n",
    "\n",
    "#Decision Tree Classifier\n",
    "giniImp = DecisionTreeClassifier(criterion = \"gini\", random_state=100)\n",
    "giniImp.fit(X_train,Y_train)\n",
    "# Making the prediction\n",
    "y_pred2 = giniImp.predict(X_test)\n",
    "display('Decision Tree Classifier Score: ', metrics.accuracy_score(Y_test,y_pred2))\n",
    "\n",
    "#KNN Classifier \n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(X_train,Y_train)\n",
    "y_pred3 = neigh.predict(X_test)\n",
    "# Making the prediction\n",
    "display('KNN Classifier Score: ', metrics.accuracy_score(Y_test,y_pred3))\n",
    "\n",
    "#Logisitic Regression Classifier\n",
    "lrmodel = LogisticRegression(multi_class = 'multinomial', solver = 'sag', C = 1000)\n",
    "lrmodel.fit(X_train,Y_train)\n",
    "# Making the prediction\n",
    "y_pred4 = lrmodel.predict(X_test)\n",
    "display('Logistic Regression Classifier Score: ', metrics.accuracy_score(Y_test,y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************Grid Search****************************************************\n",
    "#GridSearch on SVM hyperparameter  \n",
    "#define parameter range\n",
    "param_grid1 = {'C' : [1, 5, 10, 25, 50, 75, 100, 250, 500, 1000]}\n",
    "               #param_grid1 = [{'C' : [1, 5, 10, 25, 50, 75, 100, 250, 500, 1000], 'kernel': ['linear']},\n",
    "               #{'C' : [1, 5, 10, 25, 50, 75, 100, 250, 500, 1000], 'kernel': ['poly']},\n",
    "               #{'C' : [1, 5, 10, 25, 50, 75, 100, 250, 500, 1000], 'kernel': ['rbf']},\n",
    "               #{'C' : [1, 5, 10, 25, 50, 75, 100, 250, 500, 1000], 'kernel': ['sigmoid']}]\n",
    "grid1 = GridSearchCV(svclass, param_grid1, refit = True, verbose = 3, cv = 4) \n",
    "#fit the model for grid search \n",
    "grid1.fit(X_train,Y_train)\n",
    "# grid predictions\n",
    "grid_prediction1 = grid1.predict(X_test)\n",
    "\n",
    "#GridSearch on DecisionTree hyperparameter \n",
    "#define parameter range\n",
    "param_grid2 = {'max_depth' : [4, 8, 10, 12, 16, 24, 30, 34]}\n",
    "grid2 = GridSearchCV(giniImp, param_grid2, refit = True, verbose = 3, cv = 4) \n",
    "#fit the model for grid search \n",
    "grid2.fit(X_train,Y_train)\n",
    "# grid predictions\n",
    "grid_prediction2 = grid2.predict(X_test)\n",
    "\n",
    "#GridSearch on KNN hyperparameter  \n",
    "#define parameter range\n",
    "param_grid3 = {'n_neighbors' : [1, 3, 5, 7, 10, 12, 15, 16]}\n",
    "grid3 = GridSearchCV(KNeighborsClassifier(), param_grid3, refit = True, verbose = 3, cv = 4) \n",
    "#fit the model for grid search \n",
    "grid3.fit(X_train,Y_train)\n",
    "# grid predictions\n",
    "grid_prediction3 = grid3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************Grid Search Visualization*****************************************\n",
    "#1. SVM\n",
    "scores = grid1.cv_results_\n",
    "mean_scores1 = scores.get('split0_test_score')\n",
    "mean_scores2 = scores.get('split1_test_score')\n",
    "mean_scores3 = scores.get('split2_test_score')\n",
    "mean_scores4 = scores.get('split3_test_score')\n",
    "params = param_grid1.get('C')\n",
    "_, SVM_plot = plt.subplots(1,1)\n",
    "SVM_plot.plot(params, mean_scores1, '-o', label = 'Split 1')\n",
    "SVM_plot.plot(params, mean_scores2, '-x', label = 'Split 2')\n",
    "SVM_plot.plot(params, mean_scores3, '-v', label = 'Split 3')\n",
    "SVM_plot.plot(params, mean_scores4, '-^', label = 'Split 4')\n",
    "\n",
    "SVM_plot.set_title(\"Grid Search Scores: Support Vector Machines\", fontsize=16, fontweight='bold')\n",
    "SVM_plot.set_xlabel('C value', fontsize=14)\n",
    "SVM_plot.set_ylabel('Cross Validation Average Score', fontsize=14)\n",
    "SVM_plot.legend(loc=\"best\", fontsize=14)\n",
    "SVM_plot.grid('on')\n",
    "\n",
    "#2. DT\n",
    "scores = grid2.cv_results_\n",
    "mean_scores1 = scores.get('split0_test_score')\n",
    "mean_scores2 = scores.get('split1_test_score')\n",
    "mean_scores3 = scores.get('split2_test_score')\n",
    "mean_scores4 = scores.get('split3_test_score')\n",
    "params = param_grid2.get('max_depth')\n",
    "_, DT_plot = plt.subplots(1,1)\n",
    "DT_plot.plot(params, mean_scores1, '-o', label = 'Split 1')\n",
    "DT_plot.plot(params, mean_scores2, '-x', label = 'Split 2')\n",
    "DT_plot.plot(params, mean_scores3, '-v', label = 'Split 3')\n",
    "DT_plot.plot(params, mean_scores4, '-^', label = 'Split 4')\n",
    "\n",
    "DT_plot.set_title(\"Grid Search Scores: Decision Trees\", fontsize=16, fontweight='bold')\n",
    "DT_plot.set_xlabel('Max Depth', fontsize=14)\n",
    "DT_plot.set_ylabel('Cross Validation Average Score', fontsize=14)\n",
    "DT_plot.legend(loc=\"best\", fontsize=14)\n",
    "DT_plot.grid('on')\n",
    "\n",
    "#3. KNN\n",
    "scores = grid3.cv_results_\n",
    "mean_scores1 = scores.get('split0_test_score')\n",
    "mean_scores2 = scores.get('split1_test_score')\n",
    "mean_scores3 = scores.get('split2_test_score')\n",
    "mean_scores4 = scores.get('split3_test_score')\n",
    "params = param_grid3.get('n_neighbors')\n",
    "_, KNN_plot = plt.subplots(1,1)\n",
    "KNN_plot.plot(params, mean_scores1, '-o', label = 'Split 1')\n",
    "KNN_plot.plot(params, mean_scores2, '-x', label = 'Split 2')\n",
    "KNN_plot.plot(params, mean_scores3, '-v', label = 'Split 3')\n",
    "KNN_plot.plot(params, mean_scores4, '-^', label = 'Split 4')\n",
    "\n",
    "KNN_plot.set_title(\"Grid Search Scores: K-Nearest Neighbors\", fontsize=16, fontweight='bold')\n",
    "KNN_plot.set_xlabel('K value', fontsize=14)\n",
    "KNN_plot.set_ylabel('Cross Validation Average Score', fontsize=14)\n",
    "KNN_plot.legend(loc=\"best\", fontsize=14)\n",
    "KNN_plot.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion Matrix Definition\n",
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    minlabel = np.min(y_true)\n",
    "    y_true = y_true - np.repeat(minlabel, y_true.shape[0])\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred - np.repeat(minlabel, y_true.shape[0])\n",
    "    y_pred = y_pred.astype(int)\n",
    "    numClass = np.unique(y_true).shape[0]\n",
    "    confusion = np.zeros((numClass,numClass))\n",
    "    for i, j in zip(y_true, y_pred):\n",
    "        confusion[i][j] += 1    \n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************************Confusion Matrix Visualization*****************************************\n",
    "####### IMPORTANT: CONFUSION MATRICES REQUIRE Y_TESTS TO BE ADDED#######\n",
    "SVM_CM = ConfusionMatrix(Y_test, y_pred1)\n",
    "plt.matshow(SVM_CM, cmap=plt.cm.get_cmap('Blues', 10));\n",
    "plt.colorbar()\n",
    "plt.show();\n",
    "\n",
    "DT_CM = ConfusionMatrix(Y_test, y_pred2)\n",
    "plt.matshow(DT_CM, cmap=plt.cm.get_cmap('Reds', 10));\n",
    "plt.colorbar()\n",
    "plt.show();\n",
    "\n",
    "KNN_CM = ConfusionMatrix(Y_test, y_pred3)\n",
    "plt.matshow(KNN_CM, cmap=plt.cm.get_cmap('Purples', 10));\n",
    "plt.colorbar()\n",
    "plt.show();\n",
    "\n",
    "LR_CM = ConfusionMatrix(Y_test, y_pred4)\n",
    "plt.matshow(LR_CM, cmap=plt.cm.get_cmap('Greens', 10));\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors\n",
    "h = 0.2\n",
    "X = X_train[:, :2]\n",
    "y = Y_train\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap([ '#FFCCCC', '#FFE5CC', '#FFFFCC', '#E5FFCC', '#CCFFFF', '#CCE5FF', '#CCCCFF','#FFCCFF'])\n",
    "cmap_bold = ListedColormap(['#FF3333','#FF9933','#FFFF33','#80FF00','#00FFFF','#0080FF','#0000FF','#7F00FF','#FF00FF'])\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = neighbors.KNeighborsClassifier(5, weights='distance')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# calculate min, max and limits\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict class using data and kNN classifier\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(facecolor=(1, 1, 1))\n",
    "#    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"2-Class classification (k = %i)\" % (neighbors)) #labels, number of neightbors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PLOT FOR PREDICTION\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "labels = ['Move Both Fists','Imagine Moving Both Fists','Imagine Moving Left Fist','Imagine Moving Right Fist','Left Fist','Rest Eyes Closed','Rest Eyes Open','Right Fist']\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(X_train)\n",
    "neigh.fit(X_train,Y_train)\n",
    "neighbors = 5\n",
    "samp = np.array([X_test[53,]])\n",
    "idx = neigh.kneighbors(samp, neighbors*3, return_distance = False)\n",
    "idx = idx.flatten()\n",
    "neighborplot = XYsample[idx,:]\n",
    "predicted_label = labels[np.argmax(np.bincount(neighborplot[0:neighbors,-1]))]\n",
    "display(predicted_label)\n",
    "display(neighborplot[:,-1])\n",
    "y = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "colors = ['#FF3333','#FF9933','#FFFF33','#80FF00','#00FFFF','#0080FF','#0000FF','#7F00FF']\n",
    "colors2 = ['#FFCCCC', '#FFE5CC', '#FFFFCC', '#E5FFCC', '#CCFFFF', '#CCE5FF', '#CCCCFF','#FFCCFF']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "\n",
    "for i in range(samp.shape[0]):\n",
    "    for j in range(neighbors):\n",
    "        xx = np.array([neighborplot[i*neighbors+j,0],samp[i,0]]) #neighborplot[i*neighbors+j,0]\n",
    "        yy = np.array([neighborplot[i*neighbors+j,1],samp[i,1]]) #[neighborplot[i*neighbors+j,1]\n",
    "        ax.plot(xx,yy, 'r--',color = 'gray')\n",
    "for i in range(8):\n",
    "    ax.scatter(neighborplot[neighborplot[:,-1] == i,0], neighborplot[neighborplot[:,-1] == i,1], label = labels[i], marker='o', s= 100, color=colors[i], edgecolor = 'gray')\n",
    "for i in range(samp.shape[0]):\n",
    "    ax.scatter(samp[i,0], samp[i,1], marker='*', s= 750, color='black') \n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
